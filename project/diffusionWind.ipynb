{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a93294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2c4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownscalingDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, low_res_data, high_res_data, low_var_name=None, high_var_name=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            low_res_path (string): Path to the low resolution data.\n",
    "            high_res_path (string): Path to the high resolution data.\n",
    "        \"\"\"\n",
    "        self.low_res_data = low_res_data\n",
    "        self.high_res_data = high_res_data\n",
    "        self.low_var_name = low_var_name\n",
    "        self.high_var_name = high_var_name\n",
    "        \n",
    "        if len(self.low_res_data) != len(self.high_res_data):\n",
    "            raise ValueError(\"Low res and high res data must have the same length\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.low_res_data)\n",
    "\n",
    "    def get_var_name(self):\n",
    "        if self.low_var_name is None or self.high_var_name is None:\n",
    "            warnings.warn(\"Some variable names are not set\")\n",
    "        print(\"Low res variable name: \", self.low_var_name)\n",
    "        print(\"High res variable name: \", self.high_var_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        low_res = np.array(self.low_res_data[idx])\n",
    "        high_res = self.high_res_data[idx]\n",
    "\n",
    "        sample = {'low_res': low_res, 'high_res': high_res}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381f0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clean_data(out_var, in_var, year):\n",
    "    if year < 2010 or year > 2020:\n",
    "        print(\"year must be greater than 2010 and less than 2020\")\n",
    "        return\n",
    "    in_path = 'download/era5/'+in_var+'-2010_2020.nc'\n",
    "    in_data = nc.Dataset(in_path)\n",
    "    \n",
    "    # get the 3-hour of the start day from Unix timestamp\n",
    "    start_hour = datetime(2010, 1, 1, 0).timestamp()/3600/3\n",
    "    end_hour = datetime(2021, 1, 1, 0).timestamp()/3600/3\n",
    "    low_hour = datetime(year, 1, 1, 0).timestamp()/3600/3\n",
    "    high_hour = datetime(year+1, 1, 1, 0).timestamp()/3600/3\n",
    "    start_index = int(low_hour - start_hour)\n",
    "    end_index = int(high_hour - start_hour)\n",
    "    in_data = in_data[in_var][start_index:end_index]\n",
    "    out_data = np.load('download/cerra/' + out_var + '-' + str(year) + '.npy')\n",
    "\n",
    "    return in_data, out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d940f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low res variable name:  u10\n",
      "High res variable name:  si10\n",
      "2920\n",
      "(13, 21)\n",
      "(73, 101)\n"
     ]
    }
   ],
   "source": [
    "in_data, out_data = make_clean_data('si10', 'u10', 2019)\n",
    "dataset = DownscalingDataset(in_data, out_data, low_var_name='u10', high_var_name='si10')\n",
    "dataset.get_var_name()\n",
    "print(len(dataset))\n",
    "print(dataset[0][\"low_res\"].shape)\n",
    "print(dataset[0][\"high_res\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "856b7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000 # I think they use 5 for evaluation. not sure about training but 5 seems low??\n",
    "min_noise = 0.0001 # don't really know what to use for these values\n",
    "max_noise = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e1871f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From youtube tutorial. Could be re-implemented but seems good to me\n",
    "\n",
    "def linear_beta_schedule(timesteps, start, end):\n",
    "    return torch.linspace(start, end, timesteps)\n",
    "\n",
    "def get_index_from_list(vals, t, x_shape):\n",
    "    \"\"\"\n",
    "    Returns a specific index t of a passed list of values vals\n",
    "    while considering the batch dimension.\n",
    "    \"\"\"\n",
    "    batch_size = t.shape[0]\n",
    "    out = vals.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "\n",
    "def forward_diffusion_sample(x_0, t, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Takes an image and a timestep as input and\n",
    "    returns the noisy version of it\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_0)\n",
    "    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
    "    )\n",
    "    # mean + variance\n",
    "    return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n",
    "    + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n",
    "\n",
    "\n",
    "# Define beta schedule\n",
    "betas = linear_beta_schedule(timesteps=T, start=min_noise, end=max_noise)\n",
    "\n",
    "# Pre-calculate different terms for closed form\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0) # don't know why we need that\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas) # don't know why we need that\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod) # don't know why we need that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de0a095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Let's define the Unet\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2beef5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c15c7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used to get embedding of time step t to provide it as input to the model\n",
    "# so that it knows how much noise it needs to remove\n",
    "# From the youtube video. i didn't find any other way to do that online\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time): # idk if they use the same embedding in the paper's model\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        # TODO: Double check the ordering here\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7127157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    '''Downsampling block used to build Unet'''\n",
    "    def __init__(self, in_ch, out_ch, drop_p, time_emb_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding='same')\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding='same')\n",
    "        \n",
    "        self.bnorm1 = nn.BatchNorm2d(out_ch)\n",
    "        self.bnorm2 = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "        # self.drop = nn.Dropout(p=drop_p)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
    "        \n",
    "        # Time embedding\n",
    "        time_emb = self.relu(self.time_mlp(t))\n",
    "        # Extend last 2 dimensions\n",
    "        time_emb = time_emb[(..., ) + (None, ) * 2]\n",
    "        # Add time channel\n",
    "        h = h + time_emb\n",
    "        \n",
    "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
    "        \n",
    "        h = self.avgpool(h)\n",
    "        \n",
    "        # h = self.drop(h)     # not sure we wanna use dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7eb25b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    '''Upampling block used to build Unet'''\n",
    "    def __init__(self, in_ch, out_ch, drop_p, time_emb_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.upsamp = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        # 2*in_ch because residual connection\n",
    "        self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding='same')\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding='same')\n",
    "        \n",
    "        self.bnorm1 = nn.BatchNorm2d(out_ch)\n",
    "        self.bnorm2 = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "        # self.drop = nn.Dropout(p=drop_p)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        h = self.upsamp(x)\n",
    "        \n",
    "        # h = self.drop(h)     # not sure we wanna use dropout\n",
    "        \n",
    "        h = self.bnorm1(self.relu(self.conv1(h)))\n",
    "        \n",
    "        # Time embedding\n",
    "        time_emb = self.relu(self.time_mlp(t))\n",
    "        # Extend last 2 dimensions\n",
    "        time_emb = time_emb[(..., ) + (None, ) * 2]\n",
    "        # Add time channel\n",
    "        h = h + time_emb\n",
    "        \n",
    "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
    "        \n",
    "        h = self.avgpool(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f61ed666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingUnet(nn.Module):\n",
    "    '''Unet architecture denoising model'''\n",
    "    def __init__(self, nbr_channels, input_channels, output_channels, time_emb_dim):\n",
    "        super().__init__()\n",
    "        self.down_channels = tuple(nbr_channels)\n",
    "        self.up_channels = tuple(nbr_channels[::-1])\n",
    "        \n",
    "        # Not sure this is the right way to combine the blocks but I think so because\n",
    "        # they say they have 4 blocks on each side and they give 4 different numbers of\n",
    "        # channels\n",
    "        \n",
    "        self.down0 = DownBlock(input_channels, self.down_channels[0], 0.5, time_emb_dim)\n",
    "        \n",
    "        self.downs = nn.ModuleList([DownBlock(self.down_channels[i], self.down_channels[i+1], 0.5, time_emb_dim) \\\n",
    "                                   for i in range(len(self.down_channels)-1)])\n",
    "        \n",
    "        self.ups = nn.ModuleList([UpBlock(self.up_channels[i], self.up_channels[i+1], 0.5, time_emb_dim) \\\n",
    "                                   for i in range(len(self.up_channels)-1)])\n",
    "        \n",
    "        self.output = UpBlock(self.up_channels[-1], output_channels, 0.5, time_emb_dim)\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(time_emb_dim),\n",
    "                nn.Linear(time_emb_dim, time_emb_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        \n",
    "    def forward(x):\n",
    "        # Embed time\n",
    "        t = self.time_mlp(timestep)\n",
    "        \n",
    "        residuals = []\n",
    "        \n",
    "        x = self.down0(x, t)\n",
    "        residuals.append(x)\n",
    "        \n",
    "        for down in self.downs:\n",
    "            x = down(x, t)\n",
    "            residuals.append(x)\n",
    "            \n",
    "        for up in self.ups:\n",
    "            residual_x = residuals.pop()\n",
    "            x = torch.cat((x, residual_x), dim=1)\n",
    "            x = up(x, t)\n",
    "            \n",
    "        residual_x = residuals.pop()\n",
    "        x = torch.cat((x, residual_x), dim=1)\n",
    "        x = self.output(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5887e9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params:  6690576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenoisingUnet(\n",
       "  (down0): DownBlock(\n",
       "    (conv1): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (time_mlp): Linear(in_features=32, out_features=64, bias=True)\n",
       "  )\n",
       "  (downs): ModuleList(\n",
       "    (0): DownBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (bnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (time_mlp): Linear(in_features=32, out_features=128, bias=True)\n",
       "    )\n",
       "    (1): DownBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (bnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (time_mlp): Linear(in_features=32, out_features=256, bias=True)\n",
       "    )\n",
       "    (2): DownBlock(\n",
       "      (conv1): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (bnorm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bnorm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (time_mlp): Linear(in_features=32, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ups): ModuleList(\n",
       "    (0): UpBlock(\n",
       "      (upsamp): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (bnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (time_mlp): Linear(in_features=32, out_features=256, bias=True)\n",
       "    )\n",
       "    (1): UpBlock(\n",
       "      (upsamp): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (bnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (time_mlp): Linear(in_features=32, out_features=128, bias=True)\n",
       "    )\n",
       "    (2): UpBlock(\n",
       "      (upsamp): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (bnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (time_mlp): Linear(in_features=32, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (output): UpBlock(\n",
       "    (upsamp): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bnorm1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bnorm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (time_mlp): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (time_mlp): Sequential(\n",
       "    (0): SinusoidalPositionEmbeddings()\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_channels = [64, 128, 256, 384]\n",
    "input_channels = 5\n",
    "output_channels = 1\n",
    "time_emb_dim = 32 # I guess that's a standard value\n",
    "model = DenoisingUnet(unet_channels, input_channels, output_channels , time_emb_dim)\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# End of Unet\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "721712eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm first going to try creating a data loader that uses only one image as input\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "batch_size = 8 # from paper\n",
    "epochs = 200 # from paper\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-04, weight_decay=1e-05)\n",
    "up_shape = dataset[0][\"high_res\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b59c8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_lr_wd(optimizer, epoch, num_epochs):\n",
    "    '''Callback function that adjusts both the learning rate and weight decay'''\n",
    "    lr = 1e-04 * (0.1 ** (epoch / num_epochs)) # Learning rate decay from 1e-04 to 1e-05\n",
    "    wd = 1e-05 * (0.1 ** (epoch / num_epochs)) # Weight decay decay from 1e-05 to 1e-06\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        param_group['weight_decay'] = wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to implement the parts of the training loop before combining everything together\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for epoch in num_epochs:\n",
    "    callback_lr_wd(optimizer, epoch, num_epochs)\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        low_res_imgs = batch[\"low_res\"]\n",
    "        low_res_imgs = low_res_imgs.unsqueeze(1) # because one channel\n",
    "\n",
    "        # upsample to match high res shape\n",
    "        upsampled = F.interpolate(low_res_imgs, size=up_shape, mode='bilinear')\n",
    "\n",
    "\n",
    "        t = torch.randint(0, T, (batch_size,), device=\"cpu\").long() # will need to change device\n",
    "\n",
    "        # apply noise\n",
    "        noisy_x, noise = forward_diffusion_sample(upsampled, t)\n",
    "\n",
    "        noise_pred = model(noisy_x, t) # model is denoising unet\n",
    "\n",
    "        loss = F1.loss(noise, noise_pred) # is that actually the loss we have to use?\n",
    "        # doing that, we don't make use of the true high resolution data\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch = {epoch+1}/{num_epochs}.\") \n",
    "        # What measure could we use to evaluate our training?\n",
    "        # I guess the loss but it's strange in this case no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permet de visualiser les diff√©rents inputs, etc.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_windspeeds(windspeeds):\n",
    "    \"\"\"\n",
    "    Plot windspeeds\n",
    "    \n",
    "    Parameters:\n",
    "        windspeeds (torch.Tensor): Tensor representing windspeeds in a grid.\n",
    "    \"\"\"\n",
    "    # Convert the windspeeds tensor to a NumPy array\n",
    "    windspeeds_array = windspeeds.numpy()\n",
    "\n",
    "    # Plot the windspeeds using imshow\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(windspeeds_array, cmap='viridis', origin='lower')\n",
    "    plt.colorbar(label='Windspeed')\n",
    "    plt.title('Windspeeds in Grid')\n",
    "    plt.xlabel('Horizontal Index')\n",
    "    plt.ylabel('Vertical Index')\n",
    "    plt.show()\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "    low_res_imgs = batch[\"low_res\"]\n",
    "    print(\"Low resolution input:\")\n",
    "    plot_windspeeds(low_res_imgs[0,:,:])\n",
    "    low_res_imgs = low_res_imgs.unsqueeze(1) # because one channel\n",
    "    \n",
    "    # upsample to match high res shape\n",
    "    upsampled = F.interpolate(low_res_imgs, size = up_shape, mode = 'bilinear')\n",
    "    \n",
    "    print(\"Upsampled low resolution input:\")\n",
    "    plot_windspeeds(upsampled[0,:,:,:].squeeze())\n",
    "    \n",
    "    print(\"True high resolution:\")\n",
    "    high_res_imgs = batch[\"high_res\"]\n",
    "    plot_windspeeds(high_res_imgs[0,:,:])\n",
    "    \n",
    "    t = torch.randint(0, T, (batch_size,), device=\"cpu\").long() # will need to change device\n",
    "    \n",
    "    # apply noise\n",
    "    noisy_x, noise = forward_diffusion_sample(upsampled, t)\n",
    "    print(\"After applying noise:\")\n",
    "    plot_windspeeds(noisy_x[0,:,:,:].squeeze())\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
